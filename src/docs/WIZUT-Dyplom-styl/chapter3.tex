%----------------------------------------------------------------------------------------
%	CHAPTER 3
%----------------------------------------------------------------------------------------

\chapter{Opracowany algorytm}
\label{ch:opracowany-algorytm}
\chaptermark{Opracowany algorytm}
W przedstawionej pracy zrealizowano program rozpoznający tablice rejestracyjne na sekwencjach wideo pochodzących z kamery samochodowej.
Do detekcji użyto skanowania obrazu oknem przesuwnym i klasyfikowanie na podstawie cech Haara za pomocą algorytmu RealBoost.
Jako słaby klasyfikator wykorzystano algorytm koszykowania wartości funkcją logit.
Rozpoznane fragmenty obrazu zawierające tablice poddano operacjom morfologicznym.
Z przetworzonych obrazów segmentowano znaki tablicy rejestracyjnej.
Do rozpoznania znaków użyto biblioteki Tesseract opartej o rekurencyjne sieci neuronowe LSTM\@.


\section{Proces uczenia klasyfikatora}
\label{sec:proces-uczenia-klasyfikatora}
Proces uczenia klasyfikatora jest kluczowym etapem budowy modelu uczenia maszynowego.
Jeżeli na tym etapie dojdzie do błędu, będzie to rzutować na działanie całej aplikacji.
Częstym zjawiskiem w uczeniu maszynowym jest przeuczenie (ang. \textit{overfitting}).
Polega ono na wykrywaniu pozornych prawidłowości w dużej ilości danych, gdzie prawdziwe prawidłowości są prostsze lub słabsze, lub są maskowane przez błędy, lub są całkowicie nieistniejące~\cite{overfitting}.
Innym niepożądanym przypadkiem błędnego wyuczenia jest niedouczenie (ang. \textit{underfitting}).
Wynika ono najczęściej z zastosowania zbyt uproszczonego modelu lub niewystarczającej liczby próbek uczących~\cite{overfitting}.
Mając powyższe na uwadze, należy przyłożyć staranną uwagę do przygotowania odpowiedniego zbioru uczącego.
Nieprawidłowości na tym etapie będą bardzo trudno do wyeliminowania w późniejszych częściach systemu.

\subsection{Przygotowanie danych uczących}
\label{subsec:przygotowanie-danych-uczacych}
W rozdziale \ref{ch:preparing_data_set} przedstawiono opracowany zbiór zdjęć z kamery samochodowej zawierający poruszające się pojazdy wraz z ich tablicami rejestracyjnymi.
Klasyfikatory działają jednak w inny sposób niż ludzki mózg i wymagają innych wartości, na których będą mogły podejmować decyzje.
W niniejszej pracy zdecydowano się wykorzystać cechy Haara jako cechy reprezentujące poszukiwane obiekty.
W celu wyuczenia klasyfikatora, należało opracowany wcześniej zbiór przetworzyć, aby każda negatywna i pozytywna próbka miała swoją reprezentację liczbową.
Na Rysunku~\ref{fig:haar_feats_dataset_prepare} przedstawiono schemat blokowy procesu przygotowania danych uczących dla klasyfikatora.
\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.4]{Pictures/prepare_haar_dataset}
    \caption{Schemat blokowy przygotowania danych uczących dla klasyfikatora (źródło: opracowanie własne).}
    \label{fig:haar_feats_dataset_prepare}
\end{figure}
\FloatBarrier
Pierwszą czynnością jest określenie parametrów zbioru uczącego.
Przed rozpoczęciem uczenia należy określić ile cech ma być liczonych z jednej próbki.
Każdy szablon może być odpowiednią ilość razy skalowany wzdłuż każdego z kierunków.
Parametr ten oznacza się literą $s$.
Parametrem $p$ oznacza rozmiary regularnej siatki ($(2p-1)x(2p-1)$) punktów zaczepienia cech~\cite{szybka_detekcja_klesk}.
Na podstawie powyższych parametrów określa się liczbę cech niezbędnych do wyliczenia w trakcie przetwarzania jednego okna wg wzoru~\eqref{eq:features_count}.
\begin{equation}
    \label{eq:features_count}
    n(s,p)=6s^2(2p-1)^2
\end{equation}
Przykładowo, dla $s=3$ i $p=4$ liczba niezbędnych do wyliczenia cech jest równa 2205.
Dla $s=p=5$ liczba ta rośnie do 10125.
Im większa jest liczba cech tym dokładność detekcji powinna rosnąć.
Jednak wraz ze wzrostem liczby cech, rośnie też czas wykonania skryptu ze względu na większą liczbę niezbędnych do wykonania obliczeń.
Innym wejściowym parametrem jest ustalenie stosunku próbek pozytywnych do próbek negatywnych.

Po ustaleniu wejściowych parametrów, wczytywany jest plik tekstowy ze współrzędnymi tablic dla konkretnych plików.
Dla każdego rekordu w zbiorze, wczytywane jest odpowiednie zdjęcie.
Następnie algorytm iteruje po wszystkich pozytywnych próbkach znajdujących się w rozpatrywanym pliku.
Dla każdej próbki wyliczane są cechy Haara za pomocą wygenerowanych wcześniej szablonów.

W opisywanym programie użyto 5 szablonów cech Haara.
Szablony są skalowane odpowiednim skokiem zależnym od $s$.
Poniżej zamieszczono kod procedury generującej współrzędne szablonu dla każdej cechy \ref{lst:haar_cords}.
\begin{lstlisting}[language=Python, caption=Procedura generujące szablony cech Haara dla konkretnych wpsółrzędnych., label={lst:haar_cords}]
def haar_coords(s, p, indexes):
    coords = []
    f_jump = (FEATURE_MAX - FEATURE_MIN) / (s - 1)
    for t, s_j, s_k, p_j, p_k in indexes:
        f_h = FEATURE_MIN + s_j * f_jump
        f_w = FEATURE_MIN + s_k * f_jump
        p_jump_h = (1.0 - f_h) / (2 * p - 2)
        p_jump_w = (1.0 - f_w) / (2 * p - 2)
        pos_j = 0.5 + p_j * p_jump_h - 0.5 * f_h
        pos_k = 0.5 + p_k * p_jump_w - 0.5 * f_w
        single_coords = [np.array([pos_j, pos_k, f_h, f_w])]  # whole rectangle for single feature
        for white in HAAR_TEMPLATES[t]:
            white_coords = np.array([pos_j, pos_k, 0.0, 0.0]) + white * np.array([f_h, f_w, f_h, f_w])
            single_coords.append(white_coords)
        coords.append(np.array(single_coords))
    return np.array(coords, dtype=object)
\end{lstlisting}
Na Rysunku~\ref{fig:haar_feats_examples} pokazano przykładowe szablony podczas procesu uczenia.
\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.6]{Pictures/haar_tepmplates}
    \caption{Ekstrakcja cech za pomocą obrazów całkowych (źródło: opracowanie własne).}
    \label{fig:haar_feats_examples}
\end{figure}
\FloatBarrier

Po przeprocesowaniu wszystkich pozytywnych próbek, algorytm generuje negatywy.
Negatywne próbki są generowane losowo.
Losowana jest szerokość okna jako wartość w przedziale od 1 do 10 procent szerokości całego obrazu.
Wysokość okna jest zależna od szerokości.
Przyjęto, że wysokość okna powinna być równa $\dfrac{1}{3}, \dfrac{1}{4}$ lub $\dfrac{1}{5}$ szerokości.
Następnie dane są zapisywane do pliku.
W ten sposób przygotowane dane w następnym etapie posłużą do wyuczenia klasyfikatora.

\subsection{Uczenie klasyfikatora}
W niniejszej pracy zaimplementowano i wykorzystano algorytm wzmacniający RealBoost oparty o koszykowanie wartości funkcji logit.
Na wejściu metody uczącej funkcja przyjmuje cechy uczące oraz ich etykiety.
Dla każdej cechy obliczane są wartości maksymalne i minimalne.
Ustalane są one poprzez posortowanie wartości konkretnej cechy ze wszystkich próbek ze zbioru uczącego.
Algorytm dodaje odpowiedni margines, aby odrzucić skrajne wyniki.
Współczynnik ten ustalono na poziomie $0.05$.
Oznacza to, że dla zbioru o wielkości 100 próbek, odrzucone zostanie 5 pierwszych i 5 ostatnich wartości cech to wyznaczenia wartości brzegowych.
Następnie przypisywane są indeksy koszyków do poszczególnych cech.
Kolejnym krokiem jest przygotowanie indeksów, które przechowują informację o tym czy cecha dla konkretnego koszyka powiązana jest z próbką pozytywną czy negatywną.
Po przygotowaniu powyższych danych, algorytm przechodzi do wybrania najważniejszych cech z punktu widzenia klasyfikatora.
Obliczane jest to poprzez iterację po wszystkich cechach i określeniu cechy dla każdego klasyfikatora o najmniejszym błędzie.
Wyznaczane jest to za pomocą funkcji logit, która jest wyznaczana dla każdego z koszyków z osobna.
Na koniec dochodzi do reważenia wag.
Czynność jest powtarza dla każdego słabego klasyfikatora.
Algorytm \ref{lst:fit_realboostbins} ukazuje fragment metody uczącej odpowiedzialny za wyliczenie odpowiedzi dla każdego ze słabych klasyfikatorów i wyznaczenie indeksów najlepszych cech.
\begin{lstlisting}[language=Python, caption=Procedura ucząca klasyfikator RealBoostBins., label={lst:fit_realboostbins}]
w = np.ones(m) / m
for t in range(self.T_):
    j_best = None
    logits_best = None
    err_exp_best = np.inf
    for j in range(n):
        logits = np.zeros(self.B_)
        for b in range(self.B_):
            W_positive = w[indexer_positive[j, b]].sum()
            W_negative = w[indexer_negative[j, b]].sum()
            logits[b] = self.logit(W_positive, W_negative)
        err_exp = np.sum(w * np.exp(-yy * logits[X_binned[:, j]]))
        if err_exp < err_exp_best:
            err_exp_best = err_exp
            logits_best = logits
            j_best = j
    self.feature_indexes_[t] = j_best
    self.logits_[t] = logits_best
    w = w * np.exp(-yy * logits_best[X_binned[:, j_best]])
    w /= err_exp_best

\end{lstlisting}
Na Rysunku~\ref{fig:fit_realboostbins} przedstawiono schemat blokowy uczenia klasyfikatora.
\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.4]{Pictures/fit_realboostbins}
    \caption{Schemat blokowy funkcji uczącej klasyfikatora RealBoostBins (źródło: opracowanie własne).}
    \label{fig:fit_realboostbins}
\end{figure}
\FloatBarrier


\section{Schemat algorytmu}
@todo - opis schematu blokowego
Na Rysunku~\ref{fig:main_alg} przedstawiono schemat blokowy algorytmu rozpoznawania tablic rejestracyjnych.
\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.4]{Pictures/main_alg}
    \caption{Schemat blokowy algorytmu rozpoznawania tablic rejestracyjnych (źródło: opracowanie własne).}
    \label{fig:main_alg}
\end{figure}
\FloatBarrier

\subsection{Algorytm detekcji}
@todo - opis schematu blokowego
Na Rysunku~\ref{fig:detection_alg} przedstawiono schemat blokowy algorytmu detekcji tablic rejestracyjnych.
\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.4]{Pictures/detection_alg}
    \caption{Schemat blokowy algorytmu detekcji tablic rejestracyjnych (źródło: opracowanie własne).}
    \label{fig:detection_alg}
\end{figure}
\FloatBarrier

\subsection{Algorytm segmentacji i rozpoznawania znaków}
@todo - opis schematu blokowego
Na Rysunku~\ref{fig:characters_alg} przedstawiono schemat blokowy algorytmu rozpoznawania znaków.
\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.4]{Pictures/characters_alg}
    \caption{Schemat blokowy algorytmu rozpoznawania tablic (źródło: opracowanie własne).}
    \label{fig:characters_alg}
\end{figure}
\FloatBarrier
Na Rysunku~\ref{fig:segmentation} przedstawiono przykładowy proces segmentacji znaków.
Pierwszy obraz jest obrazem wejściowym, który trafił do algorytmu z detektora tablic rejestracyjnych.
Ostatni obraz jest wynikiem segmentacji.
Obraz środkowy jest obrazem wejściowym, na który nałożono wykryte pozycje znaków (kolor niebieski).
Kolorem różowym oznaczono kontury, które zostały wykryte, ale nie zostały spełniły kryteriów geometrycznych.
Założono, że kontur musi być prostokątem o dłuższych bokach zorientowanych w pionie.
Dodatkowo ustalono minimalną wartość powierzchni prostokąta.
Kolorem żółtym oznaczono kontury, które zostały odrzucone, z powodu ich zbyt dużego odchylenia od średniej wysokości konturów.
\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.4]{Pictures/segmentation}
    \caption{Proces segmentacji znaków (źródło: opracowanie własne).}
    \label{fig:segmentation}
\end{figure}
\FloatBarrier


\section{Biblioteki użyte w programie}
Środowisko Python jest niezwykle popularne m.in. ze względu na mnogość dostępnych gotowych bilbiotek.
Jednym z celów pracy było zaimplementowanie algorytmu uczącego i klasyfikującego.
Cel ten udało się zrealizować, natomiast nie byłoby to możliwe bez użycia gotowych rozwiązań do elementarnych operacji t.j. listowanie plików w katalogach, odczyt i zapis zdjęć, pobieranie pojedynczych klatek z filmu wideo czy operacje na tablicach.
Poniżej wymieniono i opisano najważniejsze oraz najczęściej używane biblioteki w opisywanej pracy.

\subsection{OpenCV}
OpenCV jest biblioteką o otwartym źródle (ang. \textit{open source}) \cite{open_cv,open_cv_docs} .
Do jej głównych zastosowań należą przetwarzanie obrazów oraz uczenie maszynowe.
W przedstawionym programie wykorzystano najnowszą dostępną wersję na moment pisania pracy $4.6.0$.
Została zaprojektowana, aby zapewnić ustandaryzowaną infrastrukturę dla aplikacji widzenia komputerowego.
Oprogramowanie dystrybuowane jest na licencji BSD.
Pierwsza wersja została opracowana w roku 1999.
Oryginalnie powstała w języku C++, natomiast istnieją biblioteki pozwalające używać jej w innych językach programowania.
Bibliotekę można podzielić na kilka głównych modułów:
\begin{itemize}
    \item Przetwarzanie obrazów - moduł zawiera zestaw metod do przeprowadzania takich operacji jak filtrowanie, przekształcenia geometryczne, zmiana przestrzeni kolorów, histogramy
    \item Przetwarzanie wideo - zestaw metod, które pozwalają na m. in. usuwanie tła, śledzenie obiektów, wykrywanie ruchu
    \item Operacje wejścia/wyjścia na wideo - wyciąganie poszczególnych klatek z wideo, kodowanie, zapis i odczyt wideo
    \item HighGUI - moduł służący do wizualizacji wyników, wyświetlania okien, zaznaczania ROI (ang. \textit{Region of interest})
\end{itemize}

Poniżej wymieniono użyte w stworzonym programie funkcje wraz z krótkim opisem ich zastosowania:
\begin{itemize}
    \item \textit{videoCapture} - przechwytywanie obrazów z pliku wideo
    \item \textit{cvtColor} - zmiana przestrzeni barw w obrazie
    \item \textit{imread} - wczytanie obrazu z pliku
    \item \textit{imshow} - wyświetlenie obrazu
    \item \textit{imwrite} - zapis obrazu do pliku
    \item \textit{rectangle} - rysowanie prostokąta na obrazie
    \item \textit{putText} - umiejscowienie tekstu na obrazie
    \item \textit{addWeighted} - połączenie dwóch obrazów poprzez nałożenie ich na siebie
    \item \textit{thresholding} - binaryzacja obrazu
    \item \textit{GaussianBlur} - wygładzanie obrazu za pomocą funkcji Gaussa
    \item \textit{Canny} - wykrywanie krawędzi za pomocą algorytmu Johna F. Canny'ego \cite{4767851}
    \item \textit{findContours} - wykrywanie konturów obiektów (punktów o tym samym kolorze lub intensywności łączących się w krzywe)
    \item \textit{resize} - zmiana wielkości obrazu
    \item \textit{imdecode} - odczytywanie zdjęcia z bufora
\end{itemize}

\subsection{Tesseract OCR}
Biblioteka Tesseract jest pakietem składającym się z programu lini poleceń \textit{tesseract} oraz silnika OCR \textit{libtesseract} \cite{tesseract}.
Tesseract powstał między rokiem 1985, a 1994 na potrzeby firmy Hewlett-Packard.
W roku 2005 firma upubliczniła bibliotekę jako rozwiązanie \textit{open-source}.
Od początku 2006 do listopada 2018 za rozwój Tesseract odpowiedzialna była firma Google.
Obecnie głównym programistą projektu jest Ray Smith.
Silnik programu oparty jest o język programowania C++.
W celu wykorzystania jej w opisywanym programie, użyto nakładki \textit{pytesseract} \cite{pytesseract}.
Autorzy deklarują, że najnowsza wersja 5, wydana w listopadzie 2021, wspiera ponad 100 języków.
Biblioteka wykorzystuje rekurencyjne sieci neuronowe LSTM (ang. \textit{Long Short-Temp Memory}) \cite{lstm}.

\subsection{Numpy}
TODO

\subsection{Sklearn}
TODO - do zastanowienia czy sklearn jest istotny w niniejszej pracy

\subsection{Pickle}
TODO

\subsection{Numba}
Biblioteka od przyspieszania kodu (jit)