%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Szablon pracy dyplomowej
% Wydział Informatyki
% Zachodniopomorski Uniwersytet Technologiczny w Szczecinie
% autor Joanna Kołodziejczyk (jkolodziejczyk@zut.edu.pl)
% Bardzo wczesnym pierwowzorem szablonu był
% The Legrand Orange Book
% Version 2.1 (26/09/2018)
%
% Modifications to LOB assigned by %JK
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	CHAPTER 1
% 	author: Joanna Kolodziejczyk (jkolodziejczyk@zut.edu.pl)
%----------------------------------------------------------------------------------------

\chapter{Wprowadzenie teoretyczne}\label{ch:wprowadzenie-teoretyczne}
\chaptermark{Wprowadzenie teoretyczne}

Na przestrzeni ostatnich lat stosowanie Systemów Automatycznego Rozpoznawania Tablic Rejestracyjnych (ARTR) (ang. \textit{Automatic Licence Plate Recognition} --- ALPR) stało się znacznie bardziej powszechne.
W większości dużych miast istnieją parkingi, gdzie po umieszczeniu opłaty za postój, przy zbliżeniu się do wyjazdu, szlaban otwiera się automatycznie po rozpoznaniu numeru rejestracyjnego pojazdu, w którym się poruszamy.
W obecnych czasach wszystkie nowoczesne systemy do zarządzania i sterowania ruchem drogowym oparte są o technologie ARTR.
Instytucje takie jak służby drogowe, dzięki rejestrowanym i przetwarzanym w czasie rzeczywistym ogromnym ilościom danych, są \\w stanie odpowiednio szybko reagować na wydarzenia na drogach takie jak kolizje, korki lub innego rodzaju utrudnienia.
Innym z możliwych przykładów zastosowania wspomnianych systemów są odcinkowe pomiary prędkości, opłaty za przejazd płatnymi drogami lub wykrywanie kierowców łamiących przepisy.
Dzięki nieustannemu rozwojowi technologii i coraz wydajniejszym komputerom, systemy stają się tańszą i łatwiej dostępną alternatywą dla systemów opartych na RFID (ang. \textit{Radio-frequency identification}), które to wymagają specjalnej etykiety do prawidłowego działania.

Rozpoznawanie tablic rejestracyjnych jest techniką polegająca na wykryciu i odczytaniu znaków z tablicy rejestracyjnych na podstawie zarejestrowanego obrazu.
Do tego celu wykorzystywany jest aparat o wysokiej rozdzielczości oraz odpowiedni program komputerowy.
Oprogramowanie otrzymuje na wejściu cyfrową reprezentację obrazu.
Dla zdjęć kolorowych każdy piksel opisany jest wartościami z palety barw RGB reprezentującymi jego barwę oraz współrzędnymi umiejscowienia w obrazie.
Dla zdjęć monochromatycznych barwy opisywane są najczęściej za pomocą wartości luminacji obrazu.

W procesie automatycznego rozpoznawania tablic rejestracyjnych pozyskany obraz jest odpowiednio przetwarzany.
Przed przejściem do rozpoznawania, obraz często jest konwertowany do skali szarości i filtrowany za pomocą filtrów (np.\ Gaussa lub średnio-przepustowego) w celu redukcji szumu.
W procesie tym można wyróżnić trzy etapy~\cite{1688109}:
\begin{itemize}
    \item \textbf{detekcję} --- określenie położenia tablicy rejestracyjnej w analizowanym obrazie,
    \item \textbf{segmentację} --- wyodrębnienie pojedynczych znaków na fragmencie obrazu ze zlokalizowaną tablicą,
    \item \textbf{identyfikację} --- rozpoznanie każdego ze znaków i przedstawienie ich w formie tekstowej, którą można później wykorzystać do dalszych działań w zależności od przeznaczenia systemu.
\end{itemize}
\FloatBarrier
Na Rysunku~\ref{fig:schemat_lpr} przedstawiono graficzną reprezentację powyższego procesu.
\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.6]{Pictures/schemat_lpr}
    \caption{Etapy procesu automatycznego rozpoznawania tablic rejestracyjnych (źródło: opracowanie własne).}
    \label{fig:schemat_lpr}
\end{figure}
\FloatBarrier
Kolejne etapy korzystają z wyników uzyskanych w poprzednich krokach, co oznacza, że błąd powstały we wcześniejszej fazie, będzie rzutował na jakość działania całego systemu.
W wielu systemach zanim dojdzie do rozpoznawania tablicy rejestracyjnej, obraz jest w pierwszej kolejności odpowiednio przetwarzany.
Powszechnie stosowanymi czynnościami są: skalowanie obrazu, modyfikacje jasności oraz redukcja zakłóceń.
W zależności od wymagań stawianych przed danym mechanizmem i środowiskiem jego działania, czynności te mogą znacznie się od siebie różnić.
Najbardziej podstawowe systemy wymagają, aby pojazd znajdował się nieruchomo w określonym miejscu.
Tego typu rozwiązania najczęściej stosowane są na parkingach, gdzie szlaban otwiera się po odczycie numerów rejestracyjnych pojazdu i potwierdzeniu opłaty za postój w zewnętrznej bazie danych.
Takie systemy pracują z reguły w środowisku o niskim poziomie zakłóceń wynikających z warunków atmosferycznych i oświetlenia.
Obecnie na rynku znajduje się wiele komercyjnych rozwiązań, które oferują wysoką dokładność (powyżej 95\%) dla tego rodzaju detekcji.
Taki rodzaj systemów ARTR nazywany systemami statycznymi.
Dużo większą złożonością charakteryzują się systemy dynamiczne, w których znacznie większą rolę odgrywają zakłócenia wynikające ze zmiennych warunków oświetlenia.
W obecnych czasach stworzenie dynamicznego systemu ARTR o wysokiej dokładności wciąż stanowi wyzwanie i jest tematem wielu prac naukowych.
Celem niniejszej pracy jest analizowanie obrazów pochodzących z kamery samochodowej, co zdecydowanie sprawia, że jest to system dynamiczny.
Poniżej przedstawiono najczęściej stosowane metody widzenia komputerowego w systemach ARTR\@.


\section{Przegląd istniejących metod detekcji tablic rejestracyjnych}
\index{Przegląd istniejących metod detekcji tablic rejestracyjnych}

Zgodnie ze słowikiem języka polskiego, definicja tablicy rejestracyjnej brzmi następująco:
\begin{definition}[Tablica rejestracyjna]
    Płytka zawierająca numery identyfikacyjne pojazdu, umieszczana z przodu i z tyłu pojazdu.
\end{definition}
Dla programu komputerowego powyższe zdanie jest niezrozumiałe.
W zadaniu detekcji tablicy rejestracyjnej, wymagane jest, aby maszyna ,,zrozumiała'' jakich obiektów należy szukać.
W tym kontekście, za definicję można uznać ,,prostokątny obszar, z dużym zagęszczeniem horyzontalnych i wertykalnych krawędzi''~\cite{824138}.
W oparciu o powyższe cechy zaprezentowano wiele algorytmów do rozwiązania zadania wykrywania tablic rejestracyjnych.
Część z nich wywodzi się z tradycyjnych metod widzenia komputerowego i metod głębokiego uczenia.
Każda z metod ma swoje zalety, ale również często ograniczenia.
W związku z tym, trudno jednoznacznie stwierdzić, która z metod jest najbardziej efektywna.

Detekcja numerów rejestracyjnych jest wyzywającym zadaniem ze względu na poniższe czynniki:
\begin{itemize}
    \item zajmowanie niewielkiego obszaru na zdjęciu przez tablicę rejestracyjną,
    \item istnienie ogromnej ilości formatów tablic rejestracyjnych (w zależności od kraju rejestracji lub rodzaju pojazdu),
    \item słabe oświetlenie, rozmazany obraz, refleksy świetlne,
    \item ruch pojazdu, zabrudzone tablice.
\end{itemize}
Tradycyjne metody widzenia komputerowego oparte są na cechach takich jak kształt, kolor, symetria, tekstury itp.\cite{9310202}.
W celu uzyskania lepszych wyników, spotyka się rozwiązania, w których łączy się wiele technik.
Poniżej wyróżniono najczęściej stosowane metody w detekcji tablic rejestracyjnych.

\subsection{Metody oparte na krawędziach (ang. \textit{edge based)}}
\label{subsec:edge-based}
W większości krajów tablice rejestracyjne posiadają prostokątny kształt.
Dla poprawienia widoczności numerów pojazdów, stosuje się kolory o wysokim kontraście dla czcionki i tła.
Dzięki temu, tablice rejestracyjne zawierają wiele równoległych i prostopadłych linii.
Z uwagi na to, znaczna część badań bazuje na podejściu opartym o wykrywanie krawędzi.
W większości przypadków kolor tablicy rejestracyjnej jest różny od koloru pojazdu.
Dzięki temu, granice tablicy zostają uznane za krawędzie.
Wiele metod wykorzystuje filtr Sobela.
Jego działania polega na dyskretnym różniczkowaniu i aproksymacji pochodnych kierunkowych intensywności obrazu.
Filtr ten składa się z dwóch macierzy o wymiarach $3\times3$~\eqref{eq:sobel_matrices} służących do detekcji krawędzi horyzontalnych i wertykalnych.
\begin{equation}
    \begin{bmatrix}
        -1 & 0 & +1 \\
        -2 & 0 & +2 \\
        -1 & 0 & +1
    \end{bmatrix}
%
    \begin{bmatrix}
        +1 & +2 & +1 \\
        0  & 0  & 0  \\
        -1 & -2 & -1
    \end{bmatrix}
    \label{eq:sobel_matrices}
\end{equation}
Zaletą takiego podejścia jest niewątpliwa łatwość użycia, natomiast jedną z głównych wad jest jego wrażliwość na szum.

Często wykorzystywaną metodą do wykrywania krawędzi obiektów w obrazach jest \textit{Binary Image Processing}~\cite{4310039}.
Technika ta polega na sprowadzenia obrazu do postaci, w której kolory pikseli przyjmują tylko dwie wartości - czarną lub białą.
Osiąga się to za pomocą ustalenia progu, który determinuje kolor piksela.
Próg wyznaczany jest na podstawie histogramu obrazu w odcieniach szarości.
Metoda ta jest użyteczna, ze względu na fakt łatwego odseparowania obiektu od tła.
Wykorzystuje ona założenie, że krawędzie tablicy są proste i poziome.
Przy zdeformowanych lub zabrudzonych tablicach, algorytm ten nie osiąga zadowalających wyników.

Inną stosowaną metodą do wykrywania linii na obrazach binarnych jest transformata Hougha~\cite{DuanBuildingAA}.
Motywacją do jej opracowania była metoda siłowa (ang. \textit{brute force}), która jest jednak znacznie bardziej zasobożerna.
Złożoność algorytmu siłowego wynosi $O(n^3)$, gdzie $n$ oznacza liczbę niezbędnych operacji do wykonania.
Transformata Hougha polega na twierdzeniu, że każda prosta może być jednoznacznie przedstawiona za pomocą dwóch parametrów.
Przestrzeń tych parametrów to właśnie przestrzeń Hougha.
Najczęściej używanymi parametrami są współczynniki $\rho$ i $\alpha$ z równania prostej w postaci normalnej~\eqref{eq:transform_hough}
\begin{equation}
    \label{eq:transform_hough}
    x\cos{\alpha} + y\sin{\alpha} = \rho.
\end{equation}
W powyższym równaniu $\rho$ jest promieniem wodzącym, natomiast $\alpha$ kątem tworzonym przez $\rho$ z osią X.
W związku z powyższym, jest to algorytm o liniowej złożoności obliczeniowej.
Można wykazać następujące własności transformacji Hougha:\\
\begin{theorem}
    Prostej przestrzeni kartezjańskiej odpowiada w przestrzeni Hougha punkt, natomiast
    punktowi przestrzeni kartezjańskiej odpowiada w przestrzeni Hougha sinusoidalna krzywa.
    Punkty leżące na tej samej prostej korespondują z sinusoidami przechodzącymi przez
    wspólny punkt w przestrzeni Hougha~\cite{hough_transform_definition}.
\end{theorem}
Zasadę transformacji ilustruje Rysunek~\ref{fig:hough_transform}.
\begin{figure}[!ht]
    \centering
    \includegraphics[scale=1]{Pictures/hough_transform.jpeg}
    \caption{Transformata Hougha (źródło:~\cite{Lin:01}).}
    \label{fig:hough_transform}
\end{figure}
\FloatBarrier

Innym spotykanym podejściem~\cite{4410602} jest stosowanie dwóch algorytmów.
Pierwszy z nich ma za zadanie wyodrębnić odcinki linii i pogrupować je na podstawie wcześniej ustalonego zbioru warunków geometrycznych.
Drugi znajduje obszary o najwyższym zagęszczeniu pionowych krawędzi.
Dzięki takiemu spojrzeniu na przedstawiony problem, uzyskane wyniki mają wysoką dokładności, szczególnie dla pojazdów znajdujących się w ruchu.
Metode oparte na krawędziach są stosowane w wielu rozwiązaniach ze względu na ich szybkość działania i prostotę.
Jednakże, rozwiązania te są silnie wrażliwe na niepożądane krawędzie i nie sprawdzają się w rozmytych i złożonych obrazach.

\subsection{Metody oparte na kolorach (ang. \textit{color based)}}
\label{subsec:color-based}
Metody oparte na kolorach bazują na fakcie, że kolor tablicy jest różny od koloru tła pojazdu.
Dla tej grupy rozwiązań, zamiast modelu barw RGB, stosuje się model HSL oparty o nasycenie koloru.
Model ten jest jednak wrażliwy na szum.

Często metody wykorzystujące kolor tablicy rejestracyjnej są używane do wyselekcjonowania kandydatów.
Innymi słowy, oznacza to wybrania obszarów obrazu, w których może znajdować się tablica rejestracyjna.
Technika ta łączona jest z innymi algorytmami, które na kolejnych etapach decydują, czy wskazany obszar rzeczywiście zawiera poszukiwany obiekt.
Do tego typu metod wykorzystywany jest m.\ in.\ algorytm \textit{Mean shift}~\cite{1520110} i logika rozmyta~\cite{Wang2008FuzzybasedAF}.

Opisywana grupa metod może zostać użyta do detekcji zdeformowanych i pochylonych tablic.
Rzadko występują one osobno w metodach detekcji, głównie ze względu na ich dużą czułość na zmiany naświetlenia.
Dodatkowo w zależności od kraju oraz przeznaczenia pojazdu, kolory tablic mogą się znacznie różnić.
Przykładowo obecnie w Polsce tablice aut elektrycznych mają kolor zielony, a samochodów zabytkowych żółty, patrz Rys.~\ref{fig:tablice}.
\FloatBarrier
\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.6]{Pictures/tablice}
    \caption{Tablice rejestracyjne w Polsce dla aut elektrycznych i zabytkowych (źródło: opracowanie własne).}
    \label{fig:tablice}
\end{figure}
\FloatBarrier

\subsection{Metody oparte na teksturach (ang. \textit{texture based)}}
\label{subsec:metody-oparte-na-teksturach}
Metody oparte na teksturach wykorzystują fakt znajdowania się znaków na tablicach rejestracyjnych.
Znaki na tablicy mają z reguły czarny kolor i znajdują się na jasnym tle tworząc duży kontrast.
Powyższa grupa algorytmów wykorzystuje wysoką częstość zmiany kolorów w obszarze występowania tablic rejestracyjnych.
W~\cite{824138} autorzy zaproponowali metodę lokalizacji tablic wykorzystując algorytm kwantowania wektorowego (ang. \textit{Vector Quantization - VQ}).
W przeciwieństwie do innych metod, które wykorzystywały krawędzie lub kontrast, metoda VQ wykorzystuje aktualną zawartość tablicy rejestracyjnej.
Autorzy wykazali bardzo wysoką skuteczność rozwiązania na poziomie 98\%.

W analizie tekstur, często stosuje się filtr Gabora.
Jest to filtr liniowy, pozwalający na przefiltrowanie obrazu z precyzyjnie dobranym zakresem częstotliwości.
Reprezentacje częstotliwości i orientacji filtrów Gabora są uważane przez wielu współczesnych naukowców zajmujących się widzeniem komputerowym za podobne do tych z ludzkiego układu wzrokowego~\cite{gabor_human_eye}.
W~\cite{gabor_lpr} zaprezentowano algorytm wykorzystujący filtr Gabora.
Jest to jednak metoda czasochłonna i nie znajduje zastosowania w systemach, w których szybkość działania jest jednym z najistotniejszych czynników.

Wszystkie metody oparte na teksturach są odporne na deformacje tablic.
Jest to kluczowa zaleta ich stosowania.
Mimo to, metody te wymagają skomplikowanych obliczeń i nie dają zadowalających efektów w złożonych środowiskach z różnymi warunkami oświetlenia.

\subsection{Klasyfikatory}\label{subsec:klasyfikatory}
Wiele badań wykorzystuje cechy Haara razem z algorytmem AdaBoost (ang. \textit{Adaptative Boosting --- AdaBoost}) do wyuczenia kaskady klasyfikatorów~\cite{9310202}.
Podejście takie zostało zaproponowane po raz pierwszy w~\cite{990517}.
Algorytm Violi-Jonesa został zaprezentowany w 2001.
Wykorzystuje on algorytm AdaBoost, który został zaproponowany w pracy~\cite{Freund1996ExperimentsWA}.
Pomimo upływu ponad 20 lat, dalej jest on powszechnie stosowany, co świadczy o jego ponadczasowości i uniwersalności.
Autorzy zaprojektowali go jako detektor twarzy, jednak jego funkcjonalność pozwala na wykrywanie dowolnych obiektów, np\. tablic rejestracyjnych, przy odpowiednim wyuczeniu.
Aby przedstawić, jak działa algorytm Violi-Jonesa, należy najpierw zrozumieć czym są cechy Haara.

Cechy Haara często są przedstawiane jako skalowalne, prostokątne szablony (Rysunek~\ref{fig:haar_feats}), używane do porównania zależności pomiędzy pikselami.
Reprezentują one zgrubne kontury obiektu.
Obraz skanowany jest oknem przesuwnym o rozmiarze zbliżonym do poszukiwanego obiektu.
Dla każdego okna obliczane są wartości cech Haara, na podstawie, których klasyfikator podejmuje decyzję.
Wartość pojedynczej cechy obliczana jest jako różnica pomiędzy średnią jasnością pikseli w zbiorze ,,białym'' i średnią jasnością pikseli w zbiorze ,,czarnym''~\cite{szybka_detekcja_klesk}.
\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.6]{Pictures/haar_feats}
    \caption{Cechy Haara używane w algorytmie Violi-Jonesa (źródło: \url{https://docs.opencv.org/4.x/d2/d99/tutorial_js_face_detection.html}).}
    \label{fig:haar_feats}
\end{figure}
\FloatBarrier
Im większa będzie liczba okien w procedurze skanującej, tym większa będzie niezbędna liczba cech do wyliczenia.
Zauważono, że cechy mogą być jednak wyznaczane w czasie stałym, niezależnym od rozmiaru okna.
W tym celu należy przygotować przed procedurą detekcji dodatkową tablicę zwaną obrazem całkowym (ang. \textit{integral image}).
Obrazem całkowym nazywamy tablicę dwuwymiarową o rozmiarze obrazu źródłowego, w której każdy element w i-tym wierszu i j-tej kolumnie przechowuje sumę pikseli z tej części obrazu, której prawym dolnym wierzchołkiem jest piksel $(i, j)$.
%\begin{figure}[!htb]
%    \centering
%    \includegraphics[scale=0.6]{Pictures/ii_cords}
%    \caption{Obraz całkowy dla punktu $(i, j)$ (źródło: \url{https://www.spoj.com/WIPING5/problems/WIPING50.pdf}).}
%    \label{fig:ii_cords}
%\end{figure}
%\FloatBarrier
Matematycznie obraz całkowy $ii(x,y)$ przedstawiamy jako:
\begin{equation}
    \label{eq:integral_image}
    ii(x,y) = \sum_{1\leq j \leq x} \sum_{1\leq k \leq y} i(j,k).
\end{equation}
%czym innym jest obliczanie sumy a czym inne szybkie obliczanie obrazu całkowego
Obliczanie obrazu całkowego z definicji~\eqref{eq:integral_image} dla każdego punktu w obrazie jest czasochłonne i charakteryzuje się złożonością obliczeniową $O(n_x^2 n_y^2)$.
Sposobem na szybsze obliczenie obrazu całkowego może być wykorzystanie wzorów rekurencyjnych~\cite{990517,10.1145/800031.808600}:
\begin{equation}
    \label{eq:integral_image_induction}
    s(j,k)=s(j, k-1)+f(j,k),
\end{equation}
\begin{equation}
    \label{eq:integral_image_induction2}
    ii(j,k)=ii(j,k-1)+s(j,k),
\end{equation}
gdzie $s(j,k)$ to skumulowana suma w wierszu, $f(j,k)$ to wartość obrazu w punkcie $(j,k)$~\cite{990517}.
Dzięki takiemu rozwiązaniu, wyznaczanie obrazu całkowego charakteryzuje się złożonością obliczeniową $O(n_x n_y)$.

Kiedy obraz całkowy został wyznaczony, obliczenie sumy jasności dla dowolnego fragmentu obrazu jest operacją o stałej złożoności obliczeniowej $O(1)$.
Aby osiągnąć złożoność niezależną od rozmiaru okna, sumę oblicza się odejmując od sumy wartości obrazu całkowego dla prawego dolnego i lewego górnego wierzchołka sumę wartości obrazu dla pozostałych wierzchołków analizowanego prostokąta.
Poniżej przedstawiono obliczenie sumy dla prostokąta rozpiętego między punktami $(x_1, y_1)$, a $(x_2, y_2)$.
\begin{equation}
    \label{eq:integral_image_x_y}
    \sum_{x_1\leq x \leq x_2} \sum_{y_1\leq y \leq y_2} i(x,y) = ii(x_2, y_2) - ii(x_1 - 1, y_2) - ii(x_2, y_1 - 1) + ii(x_1 - 1, y_1 - 1)
\end{equation}
Na podstawie powyższego wzoru można zauważyć, że wystarczą operacje tylko na 4 punktach obrazu całkowego~\cite{szybka_detekcja_klesk}.
Dla obliczenia różnicy pomiędzy sumami dwóch dowolnych prostokątów wymagane jest pobranie wartości dla 8 punktów z obrazu całkowego.
Poprzez zastosowanie skalowania szablonów i zakotwiczanie ich w różnych miejscach badanego okna, możliwe jest uzyskanie dużej (tzn.\ rzędu $10^3$ lub $10^4$) ilości cech Haara bez konieczności skalowania obrazu.
Tak duża liczba cech wymagana jest na etapie uczenia klasyfikatora.
Dzięki zastosowaniu boostingu, algorytm dokonuje selekcji znacznie mniejszej liczby cech, które zapewnią dobry opis rozpatrywanych obiektów w danym zagadnieniu detekcji.

AdaBoost (Adaptive Boosting) to jedna z technik boostingu.
Takie podejście zostało zaprezentowane po raz pierwszy w~\cite{Freund1996ExperimentsWA}.
Boostingiem nazywamy algorytm, którego zadaniem jest stworzenie mocnego klasyfikatora na podstawie wielu słabych klasyfikatorów.
Słabym klasyfikatorem jest klasyfikator, który osiąga niską dokładność, jednak wyższą od losowych wyników.
Za przykład może posłużyć rozpoznawanie płci na podstawie wzrostu.
Słaby klasyfikator mógłby bazować na założeniu, że każda osoba o wzroście 175cm lub wyższym jest mężczyzną.
Pozostała grupa osób jest kobietami.
Wiele osób ze zbioru testowego zostanie określonych błędnie, jednak dokładność klasyfikatora będzie wyższa niż 50\%.
Na poniższych schemacie przedstawiono pseudokod algorytmu uczącego AdaBoost.
\begin{algorithm}
    \caption{Algorytm uczący klasyfikatora AdaBoost}
    \begin{algorithmic}[1]
        \label{adaboost_alg}
        \Procedure{DiscreteAdaBoost}{$(x_i,y_i)$}
            \Comment{$i=1, \dots, m, y_i \in \{-1,+1\}$}
            \State Rozpocznij od jednostajnego rozkładu wag: $w_i \coloneqq \dfrac{1}{m}, i=1, \dots, m$.
            \For{\texttt{$t \coloneq 1, \dots, T$}}
                \State Naucz klasyfikator $f_t(x) \in \{-1, +1\}$ na danych uczących używając wag $w_i$.
                \State Oblicz błąd uczący:
                \State \hskip1em $\epsilon_t \coloneq \sum_{i=1}^{m} w_i[f(x_i)\neq y_i]$.
                \State Oblicz wagę klasyfikatora:
                \State \hskip1em $\alpha_t \coloneq \dfrac{1}{2} \ln \dfrac{1-\epsilon_t}{\epsilon_t}$.
                \State Aktualizuj wagi przykładów wg:
                \State \hskip1em $Z_t \coloneq \sum_{i=1}^{m} w_i \exp(-\alpha_t f_t(x_i) y_i)$,
                \State \hskip1em $w_i \coloneq \dfrac{w_i \exp(-\alpha_t f_t(x_i) y_i)}{Z_t}$.
            \EndFor
            \State \textbf{Zwróć} zbiorowy klasyfikator $F(x) \coloneq \sum_{t=1}^{T} \alpha_t f_t(x)$.
        \EndProcedure
    \end{algorithmic}
\end{algorithm}
\FloatBarrier
Algorytm przyjmuje na wejściu zbiór uczący wraz z etykietami opisującymi poszczególne elementy zbioru.
Do każdej pary uczącej $(x_i, y_i)$ przypisywana jest waga równa $w_i$.
Na początku uczenia, wszystkie wagi mają taką samą wartość, a ich suma jest równa 1.
Na koniec każdej pętli uczącej dochodzi do reważenia wag przykładów, a wagi błędnie sklasyfikowanych próbek zostają zwiększone.
Wagi ustalane są na podstawie błędu klasyfikacji $\epsilon_t$.
Dzięki temu, w następnej iteracji uczenia kolejny klasyfikator będzie mógł lepiej rozpoznawać niepoprawnie oznaczone jednostki treningowe w poprzednim kroku.
W momencie, gdy każdy klasyfikator zostanie wyuczony, AdaBoost przypisuje do nich wagi na podstawie dokładności każdego z nich.
Ostateczną odpowiedź klasyfikatora można opisać wzorem~\eqref{eq:ada_boost_clf}.
\begin{equation}
    \label{eq:ada_boost_clf}
    F(x) = \sign\left(\sum_{t=1}^{T} \alpha_t f_t(x))\right)
\end{equation}
Finalny klasyfikator zawiera $T$ słabych klasyfikatorów.
Każdy ze słabych klasyfikatorów zwraca jedną z dwóch odpowiedzi $\{-1, 1\}$.
Waga klasyfikatora, wyliczona przez AdaBoost, została określona symbolem $\alpha_t$.
Ostateczny rezultat powyższego równania można opisać jako liniowa kombinacja słabych klasyfikatorów.

Współczynnik $\alpha_t$ jest skorelowany z poziomem błędu klasyfikatora $\epsilon_t$, który to jest liczony jako liczba błędnie sklasyfikowanych próbek dzielona przez rozmiar zbioru uczącego.
Rysunek~\ref{fig:adaboost_alphacurve} przedstawia powyższą zależność.
\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.6]{Pictures/adaboost_alphacurve}
    \caption{Zależność współczynnika $\alpha$ od błędu klasyfikatora (źródło: \url{https://chrisjmccormick.files.wordpress.com/2013/12/adaboost_alphacurve.png}).}
    \label{fig:adaboost_alphacurve}
\end{figure}
\FloatBarrier
Z Rysunku~\ref{fig:adaboost_alphacurve} można odczytać, że waga rośnie wykładniczo dla klasyfikatorów o wysokiej dokładności.
Dla klasyfikatora o poziomie błędu $0.5$ waga jest równa zero.
Oznacza to, że taki klasyfikator jest równie dokładny co losowe zgadywanie, dlatego jest on ignorowany.
Dla klasyfikatorów o większym poziomie błędu, waga przyjmuje wartość ujemną.
Jeśli taki klasyfikator uzna próbkę za negatywną, ostatecznie zostanie ona oznaczona jako pozytywna.

AdaBoost jest techniką, która może zostać łączona z dowolnym algorytmem klasyfikującym, jednak nie może zostać wykorzystany jako samodzielny klasyfikator.
AdaBoost występuję w połączeniu z popularnymi wariantami słabych klasyfikatorów~\cite{szybka_detekcja_klesk}:
\begin{itemize}
    \item AdaBoost + decision stump
    \item AdaBoost + drzewka decyzyjne
    \item AdaBoost + klasyfikator liniowy (np. SVM)
    \item AdaBoost + naiwny Bayes
\end{itemize}
Głównymi zastosowaniami tej techniki jest wybór najlepszych cech z punktu widzenia klasyfikacji oraz dobór wag dla klasyfikatorów wchodzących w skład kaskady.
Dzięki selekcji cech najlepiej opisujących dany obiekt, jest odporna na zakłócenia.

Poza algorytmem AdaBoost, stosowane są również inne metody boostingu.
Jedną z nich jest Real AdaBoost, zwany również RealBoostem, zaprezentowany po raz pierwszy w~\cite{10.1023/A:1007614523901}.
Główną różnicą w stosunku do AdaBoosta, jest założenie, że słabe klasyfikatory są rzeczywistoliczbowe, a nie binarne~\cite{szybka_detekcja_klesk}.
Na poniższych schemacie przedstawiono pseudokod algorytmu uczącego RealBoost.
\begin{algorithm}
    \caption{Algorytm uczący klasyfikatora RealBoost}
    \begin{algorithmic}[1]
        \label{realboost_alg}
        \Procedure{RealAdaBoost}{$(x_i,y_i)$}
            \Comment{$i=1, \dots, m, y_i \in \{-1,+1\}$}
            \State Rozpocznij od jednostajnego rozkładu wag: $w_i \coloneqq \dfrac{1}{m}, i=1, \dots, m$.
            \For{\texttt{$t \coloneq 1, \dots, T$}}
                \State Naucz klasyfikator $f_t(x) \in \mathbb{R}$ na danych uczących używając wag $w_i$, tak aby $f_t$ minimalizowało \textit{kryterium wykładnicze} $\sum_{i=1}^{m} w_i \exp(-f_t(x_i) y_i)$ lub równoważnie aby $f_t$ było przybliżeniem połowy przekształcenia logit:
                \State \hskip1em $f_t(X) =\dfrac{1}{2}\ln\dfrac{\hat{P_w}(y=1|x)}{\hat{P_w}(y=-1|x)}$.
                \State Aktualizuj wagi przykładów wg:
                \State \hskip1em $Z_t \coloneq \sum_{i=1}^{m} w_i \exp(-f_t(x_i) y_i)$,
                \State \hskip1em $w_i \coloneq \dfrac{w_i \exp(-f_t(x_i) y_i)}{Z_t}$.
            \EndFor
            \State \textbf{Zwróć} zbiorowy klasyfikator $F(x) \coloneq \sum_{t=1}^{T} f_t(x)$.
        \EndProcedure
    \end{algorithmic}
\end{algorithm}
\FloatBarrier
Schemat ten jest bardzo podobny do schematu algorytmu AdaBoost.
W przeciwieństwie do AdaBoost, słabe klasyfikatory nie posiadają wag.
Mechanizm ważenia słabych klasyfikatorów jest niejako wpleciony w same odpowiedzi rzeczywistoliczbowe~\cite{szybka_detekcja_klesk}.
Odpowiedź słabego klasyfikatora jest zwykle ustalana jako przybliżenie połowy przekształcenia logit:
\begin{equation}
    \label{eq:real_boost}
    f_t(X) =\dfrac{1}{2}\ln\dfrac{\hat{P_w}(y=1|x)}{\hat{P_w}(y=-1|x)},
\end{equation}
gdzie $\hat{P_w}(y=\pm1|x)$ stanowi oszacowanie rozkładu klas warunkowego na $x$ z wykorzystaniem aktualnych wag $w_i$.
Ostateczną odpowiedź klasyfikatora można opisać wzorem~\eqref{eq:real_boost_clf}.
\begin{equation}
    \label{eq:real_boost_clf}
    F(x) = \sign\left(\sum_{t=1}^{T} f_t(x))\right)
\end{equation}
Algorytm RealBoost posiada silne podobieństwa do techniki regresji logistycznej.
Schemat reważenia w boostingu pracuje sposób pokrewny do rezyduów błędów (ang. \textit{error residuals}).

Słabe klasyfikatory stosowane w algorytmach boostingowych mogą być realizowane poprzez koszykowanie wartości funkcji logit (ang. \textit{response binning}).
Ten typ klasyfikatora został zaprezentowany w~\cite{1689652}.
Przedstawiony sposób działania polega na przybliżaniu rozkładów warunkowych przez funkcje kawałkami stałe~\cite{szybka_detekcja_klesk}.
Przed uczeniem algorytmu wyznaczana jest liczba koszy o równej szerokości oznaczana literą $B$.
Na podstawie ustalonych przedziałów $[a_1,a_2]$, każdej z cech przypisywany jest odpowiedni indeks kosza.
Indeks kosza $\beta(x) \in \{1,\dots,B\}$, do którego należy $x$ obliczany jest na podstawie wzoru~\eqref{eq:bin_index}.
\begin{equation}
    \label{eq:bin_index}
    \beta(x)=\left.
    \begin{cases}
        B(x - a_1)/(a_2-a_1), & \text{dla } a_1 \leq x \leq a_2 \\
        1, & \text{dla } x \leq a_1 \\
        B, & \text{dla } a_2 < x
    \end{cases}
    \right.
\end{equation}
Odpowiedź słabego klasyfikatora dla $j^*$-tej cechy przedstawia wzór~\eqref{eq:bin_weak_clf}, gdzie $\hat{P_w}(y=-1, j\;\text{jest}\;w\;b)=\sum_{\{i:y_i=-1,\beta(x_{ij})=b\}}^{} w_i$ oznacza szacowane prawdopodobieństwo zdarzenia, że przykład jest negatywny, a jego $j$-ta cecha należy do kosza $b$.
\begin{equation}
    \label{eq:bin_weak_clf}
    f_t(x;j^*) = \dfrac{1}{2} \ln\dfrac{\hat{P_w}(y=1, j^*\;\text{jest}\;w\;\beta(x_{j^*}))}{\hat{P_w}(y=-1, j^*\;\text{jest}\;w\;\beta(x_{j^*}))}
\end{equation}
Autorzy algorytmu zalecają stosowanie dużej ilości koszy dla gładkiego histogramu rozkładu cech.
Jeżeli histogram zawiera wiele maksimów lokalnych, należy zmniejszyć liczbę koszyków.
W przeciwnym razie zbyt duża rozdzielczość może wprowadzić szum do klasyfikatora, natomiast zbyt niska liczba koszy może pozbawić klasyfikatora istotnych cech~\cite{1689652}.

%nie wiem czy to ma tutaj sens ale niech bedzie
We wspomnianym wcześniej algorytmie Violi-Jonesa wykorzystano boosting techniką AdaBoost.
Autorzy zaproponowali użycie kaskady klasyfikatorów.
Takie podejście bazuje na obserwacji, że okna pozytywne stanowią średnio $0.01\%$ wszystkich okien.
Rozpatrywane okno w pierwszej kolejności badane jest przez słabsze klasyfikatory, które bazują na mniejszej liczbie cech.
Dzięki takiemu podejściu algorytm stał się bardziej wydajny czasowo.
Każdy kolejny klasyfikator w kaskadzie oblicza większą liczbę cech.
Jeżeli na którymś etapie klasyfikator zwróci odpowiedź negatywną, proces jest przerywany.
Do osiągnięcia pozytywnego wyniku, wymagane jest zwrócenie przez wszystkie klasyfikatory odpowiedzi pozytywnej.
W algorytmie Violi-Jonesa kaskada składa się z 32 klasyfikatorów, które badają od 2 do 200 cech.
Łącznie liczone jest 4297 cech, co daje średnio 8 cech na klasyfikator.
Algorytm jest ceniony za szybkość detekcji.
Pomimo faktu, że jego dokładność jest niższa od dokładności nowoczesnych metod opartych na sieciach neuronowych, stosowany jest on w rozwiązaniach o ograniczonej mocy obliczeniowej.
Wynika to z faktu, że algorytm Violi-Jonesa jest bardzo wydajny oraz bazuje na stosunkowo niewielkiej liczbie cech.

\subsection{Metody głębokiego uczenia (ang. \textit{Deep learning})}
W związku z rozwojem dziedziny widzenia komputerowego oraz wzrostem mocy komputerów na przestrzeni ostatnich lat, wiele metod statystycznych zostało zastąpionych przez sieci neuronowe z powodu ich wysokiej skuteczności w rozpoznawaniu obiektów.
Jednym z zaproponowanych podejść jest użycie sieci splotowych (ang. \textit{Convolutional Neural Network} --- CNN)~\cite{cnn_detector}.
Składają się one z jednej lub wielu warstw splotowych (typowych dla kroku próbkowania, określającego subwzorce), a następnie przez jedną lub w pełni połączone warstwy tak jak w klasycznej wielowarstwowej sieci.
Sieci splotowe są łatwe do uczenia, gdyż zawierają mniej parametrów (wykorzystując te same wagi) niż typowe sieci neuronowe z dokładnością do ilości warstw splotowych i ich rozmiaru.
Ten rodzaj sieci neuronowych jest predestynowany do obliczeń na strukturach 2D (tj\. obrazy)~\cite{cnn_agh}.

Jednym z najnowocześniejszych systemów detekcji w czasie rzeczywistych jest algorytm YOLO (ang. \textit{You only look once})~\cite{7780460}.
Algorytm jest bardzo wydajny.
Bazuje on na odpowiednio zaprojektowanym zadaniu regresji do predykcji tzw.\ bounding boxów obiektów.
Autorzy zapewniają o możliwości przetwarzania 45 klatek na sekundę, a dla wersji szybszej, lecz o niższej dokładności, ponad 150 klatek na sekundę.
W przeciwieństwie do tradycyjnych metod z oknem przesuwnym, YOLO podczas procesu uczenia i testowania otrzymuje na wejściu cały obraz.
Na obraz wejściowy nałożona zostaje siatka o rozmiarze $S\times S$, która tworzy obwiednie, a następnie wykorzystuje je do rozpoznawania szukanych obiektów.
Dla każdej uzyskanej ramki, mechanizm wyznacza prawdopodobną klasę.
Ramki o prawdopodobieństwie wyższym od ustalonego progu, zostają nałożone na wejściowy obraz, najczęściej w postaci prostokątów otaczających obiekt.
Rysunek~\ref{fig:yolo} przedstawia opisany schemat.
Ograniczenia YOLO wynikają z ograniczeń przestrzennych algorytmu.
W zależności od wielkości siatki, system może mieć problem z wykryciem mniejszych obiektów takich jak np. stado ptaków.
Algorytm jest stale udoskonalany przez autorów.
Na moment pisania pracy, udostępniona została trzecia wersja systemu.
\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.4]{Pictures/yolo}
    \caption{Algorytm YOLO (źródło: \url{https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e}).}
    \label{fig:yolo}
\end{figure}
\FloatBarrier


\section{Przegląd istniejących metod segmentacji tablic rejestracyjnych}
\index{Przegląd istniejących metod segmentacji tablic rejestracyjnych}

Drugim etapem w większości systemów Automatycznego Rozpoznawania Tablic Rejestracyjnych jest rozpoznanie znaków na tablicy rejestracyjnej zlokalizowanej w poprzednim kroku.
Zanim dojdzie do klasyfikacji znaków, często są one wpierw segmentowane.
Jest to szczególny przypadek optycznego rozpoznawania znaków~\cite{9310202}.
Wiele krajów posiada ścisłe regulacje na temat czcionki i kolorów tablicy rejestracyjnej.
Przepisy te mają na celu zwiększenie czytelności znaków identyfikujących każdy pojazd.
W Polsce, jak i większości krajów na świecie, tablice pokryte są specjalną warstwą refleksyjną odbijającą światło.
Działanie takie zwiększa ich czytelność dla ludzkiego oka w gorszych warunkach oświetleniowych.
Efektem takiej cechy tablic, może być ich nieczytelność na zdjęciu wykonanym aparatem fotograficznym.
Tablica odbija na tyle dużą ilość światła, co skutkuje powstaniem na zdjęciu białego prostokąta w miejscu tablicy.
Przykład takiego obrazu przedstawia Rysunek~\ref{fig:refleks_swietlny}.
\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.8]{Pictures/refleks_świetlny}
    \caption{Refleks świetlny występujący w niewystarczających warunkach oświetleniowych (źródło: opracowanie własne).}
    \label{fig:refleks_swietlny}
\end{figure}
\FloatBarrier
Poza powyższymi trudnościami, tablice mogą być obrócone lub uszkodzone.
Tablice często zawierają również śruby mocujące, które mogą utrudnić proces segmentacji.
Aby zwiększyć w jak największym stopniu prawdopodobieństwo prawidłowego odczytania znaków, używa się szereg czynności na obrazie wejściowym.
Na przykład dla obróconych obiektów stosuje się transformatę biliniową, zwaną również metodą Tustina~\cite{Xu2006AMO}.

\subsection{Binaryzacja}\label{subsec:binaryzacja}
W wielu klasycznych metodach widzenia komputerowego, w celu segmentacji znaków, stosuje się binaryzację.
W zbinaryzowanym obrazie łatwiej jest rozdzielić znaki w porównaniu do obrazu kolorowego lub w skali szarości.
Podstawowym problemem tej techniki jest odpowiedni dobór wartości progu.
Wybór ten jest dokonywany w oparciu o różne metody, które można podzielić na zmiennoprogowe i automatyczne.
Jednakże, wyznaczenie progu binaryzacji musi zostać wykonane właściwie, w celu uniknięcia połączenia znaków lub scalenia ich z obramowaniem tablicy rejestracyjnej~\cite{6213519}.
Jedną z częściej stosowanych metod binaryzacji jest progowanie adaptacyjne (ang. \textit{Adaptive Thresholding}).
Stosuje się je w momencie kiedy różne obszary obrazu mogą charakteryzować się odmiennymi warunkami oświetlenia i stosowanie stałej wartości nie dałoby zadowalających efektów.
Algorytm wyznacza próg dla konkretnego piksela na podstawie niewielkiego regionu wokoło.
Dla tego samego obrazu wyliczane są różne wartości progu dla różnych regionów, co prowadzi do uzyskania lepszych wyników niż w przypadku stałego progu binaryzacji.
Na Rysunku~\ref{fig:threshold} przedstawiono przykłady binaryzacji obrazu stałym progiem globalnym i progiem wyznaczonym adaptacyjnie.
\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.6]{Pictures/threshold}
    \caption{Przykład binaryzacji obrazu przy niejednorodnym oświetleniu za pomocą globalnego i lokalnego progu (źródło: \url{https://docs.opencv.org/3.4/d7/d4d/tutorial_py_thresholding.html}).}
    \label{fig:threshold}
\end{figure}
\FloatBarrier

Algorytm progowania adaptacyjnego otrzymuje najczęściej na wejściu obraz w skali szarości lub kolorowy.
Próg jest wyliczany dla wszystkich pikseli w obrazie z osobna.
Jednym ze znanych podejść jest to zaproponowane przez Chow i Kaneko~\cite{Chow1971BoundaryDO}.
W tym przypadku obraz dzielony jest na zbiór nakładających się fragmentów.
Optymalny próg wyznaczany jest dla konkretnego fragmentu na podstawie analizy histogramu.
Próg dla każdego piksela wyliczany jest na podstawie interpolacji wyników dla odpowiedniego fragmentu.
Wadą tej metody jest jej złożoność obliczeniowa.
Jest to jeden z głównych powodów, dlaczego algorytm ten nie znalazł zastosowania w aplikacjach działających w czasie rzeczywistym.

Alternatywnym podejściem do znalezienia lokalnego progu jest statystyczne zbadanie intensywności sąsiedztwa każdego piksela.
Wybór metody statystycznej jest skorelowany z obrazem wejściowym.
Najczęściej używa się średniej, mediany, średniej z wartości maksymalnej i minimalnej badanego otoczenia lub funkcji Gaussa.
Dobór wielkości sąsiedztwa ma duży wpływ na wyliczenie progu.
Rozmiar musi być na tyle duży, aby zawierać zarówno piksele tła jak i badanego obiektu.
Z drugiej strony, wybranie zbyt dużych obszarów może naruszyć założenie o równomiernym oświetleniu rozpatrywanego fragmentu.
Ten rodzaj progowania adaptacyjnego jest bardziej wydajny od algorytmu Chow i Kaneko.
Charakteryzuje się wysoką jakością oddzielania obiektów od tła i znajduje szerokie zastosowanie w wielu aplikacjach.

Innym znanym algorytmem stosowanym do wyznaczania progu binaryzacji jest algorytm Otsu~\cite{4310076}.
Metoda Otsu jest techniką opartą na wariancji w celu znalezienia wartości progowej, przy której ważona wariancja między pikselami pierwszego planu i tła jest najmniejsza~\cite{otsu_article}.
Kluczową ideą jest tutaj iteracja przez wszystkie możliwe wartości progu i pomiar rozproszenia pikseli tła i pierwszego planu.
Następnie znajdowany jest próg, w którym rozproszenie jest najmniejsze.
Algorytm iteracyjnie wyszukuje próg, który minimalizuje wariancję wewnątrz klasy, zdefiniowaną jako ważona suma wariancji dwóch klas (tła i pierwszego planu).
Wzór na znalezienie wariancji wewnątrz klasowej przy dowolnym progu $t$ jest określony wzorem~\eqref{eq:otsu_variance}
\begin{equation}
    \label{eq:otsu_variance}
    \sigma^2(t)=\omega_{bg}(t)\sigma_{bg}^2(t)+\omega_{fg}(t)\sigma_{fg}^2(t),
\end{equation}
gdzie $\omega_{bg}(t)$ i $\omega_{fg}(t)$ reprezentują prawdopodobieństwo liczby pikseli dla każdej klasy przy progu $t$, natomiast $\sigma^2$ oznaczono wariancję wartości kolorów.
Wyliczanie wariancji dla konkretnej klasy pikseli przedstawiono na wzorze~\eqref{eq:otsu_variance_value}.
\begin{equation}
    \label{eq:otsu_variance_value}
    \sigma_{bg | fg}^2(t)=\dfrac{\sum_{}^{}(x_i-\hat{x})^2}{N-1}
\end{equation}
Wartość piksela odpowiedniej klasy reprezentuje symbol $x_i$, natomiast $\hat{x}$ reprezentuje średnią pikseli rozpatrywanej klasy.
Liczbę wszystkich pikseli zapisano literą $N$.

Metoda Otsu implementowana jest przez wiele środowisk obliczeniowych (np. MATLAB)~\cite{otsu_inzynieria_rolnicza}.
Algorytm szczególnie dobrze sprawdza się w przypadkach, gdy liczby pikseli tła i obiektów pierwszego planu są zbliżone~\cite{10.1117/1.1631315}.

\subsection{Metoda rzutu jasności}
W kontekście segmentacji znaków, metoda rzutu jasności wykonywana jest na fragmencie obrazu potencjalnie zawierającym tablicę rejestracyjną.
W celu obliczenia rzutu jasności, sumowane są wartości pikseli w kolumnach dla obrazu w skali szarości.
Możliwe też jest generowanie rzutów jasności w poziomie, natomiast taka technika ma większe zastosowanie w detekcji tablic.
Rysunek~\ref{fig:hist_projection} przedstawia działanie metody pionowego rzutu jasności.
\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.6]{Pictures/hist_projection}
    \caption{Pionowy rzut jasności dla obrazu tablicy rejestracyjnej (źródło: opracowanie własne).}
    \label{fig:hist_projection}
\end{figure}
\FloatBarrier
Dolna część rysunku przedstawia rozkład ilości ciemnych pikseli w danej kolumnie obrazu.
Dla wyższej liczby ciemnych pikseli, linie rzutu jasności przyjmują wyższe wartości.
Przerwy pomiędzy znakami są wyraźnie widoczne na wykresie.
Na tej podstawie, możliwe jest osiągnięcie segmentacji znaków.
Powyższy przykład zawierał jednak idealnie wyciętą tablicę rejestracyjną.
W rzeczywistych systemach często zdarza się, że potencjalne fragmenty zawierające tablice mają większy rozmiar niż sama tablica.
Może to wynikać z powiększania zlokalizowanego obszaru w celu uniknięcia przycięcia tablicy przez algorytm detekcji.
Ograniczeniem tej metody jest wymaganie równoległości tablicy do krawędzi obrazu.
Dodatkowo, dla niektórych liter, widoczne są minima lokalne wynikające z ich budowy, co może prowadzić do błędnej interpretacji wyników~\cite{Półrolniczak_2012}.

\subsection{Pozostałe metody}
Wyodrębnienie znaków od tła jest problemem rozważanym w wielu pracach.
Wciąż poszukiwane są sposoby segmentacji o wyższej skuteczności niż te obecnie stosowane.
W~\cite{686064} autorzy skanowali w poziomie obraz binarny, w celu znalezienia obszarów, w których stosunek pikseli tła do pikseli znaków przekraczał predefiniowany próg.
Jeżeli takie miejsce znaleziono, uznawano je za początek znaku.
Dla odnalezienia końca znaku wykonywano odwrotną procedurę.

W pracy~\cite{1381137} zaproponowano podejście bazujące na cechach geometrycznych tablicy rejestracyjnej.
Odnalezioną tablicę skalowano to stałego rozmiaru.
Dzięki znajomości wymiarów tablicy, stosunku wysokości znaków i tablicy oraz miejsca, w którym rozpoczyna się numer rejestracyjny, próbowano dokonać segmentacji znaków.
Taki sposób jest łatwy w implementacji, natomiast jest ściśle powiązany z konkretnym formatem tablic i nie nadaje się do użycia dla różnych rodzajów.

W~\cite{segmentation_kmeans} zaprezentowano technikę segmentacji opartą o algorytm k-średnich~\cite{1017616}.
Główna idea wyglądała następująco:
\begin{enumerate}
    \item Wybranie w obrazie $k$ środków losowo,
    \item Przypisanie każdego z pikseli w obrazie do jednego z klastrów na podstawie parametru podobieństwa (np. odległości Euklidesowej),
    \item Przekalkulowanie środków klastrów poprzez uśrednienie wszystkich pikseli w klastrze,
    \item Powtórzenie kroku 2 i 3, do momentu kiedy piksele przestaną zmieniać klastry.
\end{enumerate}
Dokładność takiego rozwiązania jest mocno skorelowana z odpowiednim wyborem $k$ oraz początkowym zbiorze klastrów.
W celu właściwego wyboru $k$, autorzy użyli algorytmu SIFT (ang. \textit{Scale Invariant Feature Transform --- SIFT})~\cite{sift}.
Algorytm ten jest odporny na skalę i rotację obrazu.
Zaproponowana technika uzyskała wysoką dokładność segmentacji na poziomie $98.82\%$.


\section{Przegląd istniejących metod rozpoznawania tablic rejestracyjnych}
\index{Przegląd istniejących metod rozpoznawania tablic rejestracyjnych}
W wyniku operacji segmentowania znaków, otrzymywane są obrazy z oddzielonymi znakami od tła.
Kolejną częścią automatycznego systemu rozpoznawania tablic rejestracyjnych jest odczytanie numeru identyfikującego dany pojazd.
Jest to ostatni etap w systemie.
Rezultat tego działania przeważnie wysyłany jest już do innego modułu lub systemu odpowiedzialnego za logikę biznesową danego rozwiązania.

Optyczne rozpoznawanie znaków (ang. \textit{Optical Character Recognition} --- OCR) jest obszerną dziedziną algorytmów przetwarzających obraz na tekst.
Systemy te potrafią zarówno odczytywać tekst drukowany jak i pisany odręcznie.
Zeskanowanie dokumentów i przetworzenie ich na tekst jest już dzisiaj dość powszechną operacją.
Dzieje się tak, ponieważ proces ten zachodzi w kontrolowanych warunkach.
W dynamicznym systemie rozpoznawania numerów rejestracyjnych prawidłowe odczytanie znaków jest znacznie trudniejsze.
Jest to zagadnienie pojawiające się w wielu pracach naukowych.
Poniżej przedstawiono najczęściej stosowane metody do realizacji tego zadania.

\subsection{Metody oparte na sieciach neuronowych}
\label{subsec:neural_networks}
W pracy~\cite{1688109} autorzy przedstawili system OCR oparty o wykorzystanie probabilistycznej sieci neuronowej (ang. \textit{Probabilistic Neural Network } --- PNN).
Sieć PNN jest rozwiązaniem pamięciowym identyfikacji obiektów~\cite{Praczyk_2011}.
Klasyfikacja obiektów przy pomocy sieci PNN realizowana jest za pomocą funkcji decyzyjnej~\cite{SPECHT1990109}:
\begin{equation}
    \label{eq:pnn_network}
    f(x)=\dfrac{1}{n}\sum_{i=1}^{n}\exp\left[ -\left( \dfrac{d(x,x_i)}{p\rho} \right)^2 \right],
\end{equation}
gdzie:
\begin{itemize}
    \item $d$ jest odległością euklidesową pomiędzy wektorami identyfikowanego obiektu $x$ o i-tego przykładu uczącego $x_i$,
    \item $n$ jest liczbą wektorów uczących danej kategorii,
    \item $p$ jest rozmiarem wektora $x$ oraz wszystkich wektorów $x_i$,
    \item $\rho$ jest parametrem kształtu.
\end{itemize}
Ostateczna decyzja o przyporządkowaniu obiektu reprezentowanego przez wektor $x$ do kategorii j-tej opiera się na relacji przedstawionej na wzorze~\eqref{eq:pnn_relation}~\cite{Praczyk_2011}
\begin{equation}
    \label{eq:pnn_relation}
    h_j c_j f_j(x) > h_k c_k f_k(x) \qquad \forall j\neq k,
\end{equation}
gdzie:
\begin{itemize}
    \item $h_j$ oznacza prawdopodobieństwo a prori przynależności obiektu do j-tej klasy,
    \item $c_j$ oznacza koszt błędnej klasyfikacji obiektu należącego do j-tej kategorii.
\end{itemize}
W sieci PNN wyróżnia się trzy warstwy.
Pomiędzy warstwami wejściowym i wyjściowymi, znajduje się warstwa radialna, zawierająca neurony radialne.
Każdy neuron można określić jako funkcje radialną z centrum nad swoim przypadkiem uczącym~\cite{Praczyk_2011}.
Warstwa zawiera liczbę neuronów równej liczbie wzorców w ciągu uczącym.
Na wyjściu sygnały pochodzące z neuronów są sumowane.
Sygnał wyjściowy jest normalizowany, w taki sposób, iż suma na wszystkich wyjściach sieci jest równa 1.
Wartość pojedynczego wyjścia odpowiada prawdopodobieństwu kategorii przypisanej do tego wyjścia~\cite{Lexicon_on_Neural_networks}.
Rysunek~\ref{fig:pnn_architecture} przedstawia architekturę zaproponowanej sieci PNN w~\cite{1688109}.
Autorzy zaraportowali dokładność rozpoznawania znaków na poziomie $89.1\%$
\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.6]{Pictures/pnn_architecture}
    \caption{Architektura sieci PNN (źródło:~\cite{1688109}).}
    \label{fig:pnn_architecture}
\end{figure}
\FloatBarrier

Innym rodzajem sieci wykorzystywanych w celu rozpoznawania znaków jest sieć LSTM (ang. \textit{Long Short-Term Memory} --- LSTM)~\cite{6795963}.
Jest to szczególny rodzaj rekurencyjnych sieci neuronowych (ang. \textit{Recursive Neural Networks} --- RNNs).
Bazują one na wykorzystaniu informacji sekwencyjnych.
W tradycyjnych sieciach wszystkie wejścia i wyjścia są od siebie niezależne.
W sieciach rekurencyjnych dane wyjściowe zależą od poprzednich obliczeń.
Przykładowo chcąc przewidzieć kolejny wyraz w zdaniu, istotne jest wiedzieć, które wyrazy pojawiły się do tej pory~\cite{lawrynowicz_lstm}.
Sieci RNN posiadają zdolność ,,pamiętania" wcześniej obliczonych informacji~\cite{lawrynowicz_lstm}.
Natomiast im upłynął dłuższy czas od przetworzenia pewnej informacji, komórki sieci stopniowo ,,zapominają" tą informację.
Sieci LSTM zostały zaprojektowane do rozwiązania problem zaniku pierwszych wejść.
Rysunek~\ref{fig:lstm} przedstawia architekturę komórki sieci LSTM\@.
\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.6]{Pictures/lstm}
    \caption{Architektura komórki sieci LSTM (źródło:~\cite{10.5555/3153997}).}
    \label{fig:lstm}
\end{figure}
\FloatBarrier
Kluczową ideą sieci jest jej możliwość nauczenia się co warto przechowywać w stanie długoterminowym, co z niego usunąć i co z niego czytać~\cite{lawrynowicz_lstm}.
Stan komórki sieci LSTM jest podzielony na dwa wektory $h^{(t)}$ i $c^{(t)}$, odpowiadające odpowiednio stanowi krótko- i długoterminowemu.
Literą $t$ oznaczono daną chwilę czasu.
Wyróżnia się trzy bramki: wejściową, wyjściową oraz ,,zapomnij''.
Stan długoterminowy $c^{(t-1)}$ przemierza sieć od lewej do prawej, porzucając niektóre wspomnienia w bramce ,,zapomnij", a następnie dodając nowe.
Wspomnienia dodawane są przez bramkę wejściową.
Po operacji dodawania, stan długoterminowy jest kopiowany i przechodzi przez funkcję $\tanh$.
Ostatecznie wynik jest filtrowany przez bramkę wyjściową.
Stan krótkoterminowy $h^{(t)}$ powstaje jako stan równy wyjściu dla kroku czasowego $y^{(t)}$.
Wektor wejściowy $x^{(t)}$ oraz poprzedni stan krótkoterminowy $h^{(t-1)}$ przekazywane są do warstwy głównej oraz trzech warstw kontrolerów bramkowych.
Warstwy te są w pełni połączone.
Kontrolery bramkowe używają logistycznej funkcji aktywacji.
Na ich wyjściu wartości są z zakresu od 0 do 1.

W zastosowaniach OCR, ten rodzaj sieci pracuje na poziomie znaku.
Oznacza to, że sieci LSTM mogą być wykorzystywane do rozpoznawania tekstu niezależnie od użytego języka.
Na przestrzeni ostatnich lat pojawiło się wiele opracowań wykorzystujących sieci LSTM do realizacji systemów OCR~\cite{10.1109, 8563237}.
Warto również wspomnieć, że jedna z najpopularniejszych bibliotek programistycznych Tesseract~\cite{tesseract} od wersji 4 wykorzystuje sieci LSTM\@.

%tesseract korzysta z sieci lstm wiec warto by to opisać i jakieś inne sieci
%%https://bulldogjob.pl/readme/3-typy-rekurencyjnych-sieci-neuronowych

\subsection{Metody oparte na wzorcach}
Jedną z popularnych technik klasyfikacji znaków jest metoda oparta na wzorcach (ang. \textit{template matching})~\cite{1219663, 1217917}.
Bazuje ona na założeniu, że czcionka oraz rozmiar znaków na tablicy jest znany.
Dopasowanie wzorca odbywa się z reguły na zbinaryzowanym obrazie.
Dla każdego możliwego znaku, tworzony jest odpowiedni wzorzec.
Podczas procesu rozpoznawania, każdy wzorzec badany jest pod kątem podobieństwa do rozpatrywanego znaku.
Za miarę podobieństwa służą najczęściej~\cite{9310202}:
\begin{itemize}
    \item odległość Mahalanobisa,
    \item indeks Jaccarda,
    \item metryka Hausdorffa,
    \item odległość Hamminga,
    \item korelacja wzajemna.
\end{itemize}
Rysunek~\ref{fig:ocr_template_matching} przedstawia schemat opisywanej techniki na przykładzie litery $B$.
\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.3]{Pictures/ocr_template}
    \caption{Rozpoznanie litery B za pomocą wzorców (źródło:~\cite{Li1993AnIO}).}
    \label{fig:ocr_template_matching}
\end{figure}
\FloatBarrier
Cyfrową reprezentacją znaku jest tablica, gdzie 1 to punkt wchodzący w skład znaku, a 0 to tło.
Tablica musi mieć ten sam rozmiar co tablica wzorca, więc obrazy są najczęściej skalowane.
Dla litery $A$ wykryto 17, a dla litery $C$ 6 niepoprawnych punktów.
Metoda ta jest stosunkowo prosta w implementacji.
Problematyczne stają się różne czcionki.
Aby umożliwić rozpoznawanie wielu formatów oraz zniwelować rotację znaków, dodaje się nowe wzorce.
To z kolei zwiększa złożoność obliczeniową systemu i zapotrzebowanie na pamięć operacyjną~\cite{9310202}.